import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.manifold import TSNE
from sklearn.utils.class_weight import compute_class_weight

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications import EfficientNetB2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2


# -------------------------------------------------------
# CONFIG
# -------------------------------------------------------
DATA_DIR = 'D:/ML/dataset_classes'
IMAGE_SIZE = (260, 260)
BATCH_SIZE = 32
NUM_EPOCHS = 5
# -------------------------------------------------------
# DATA LOADING & AUGMENTATION
# -------------------------------------------------------
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=25,
    zoom_range=0.25,
    width_shift_range=0.15,
    height_shift_range=0.15,
    brightness_range=[0.85, 1.25],
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = train_datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
val_generator = val_datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# Class weights (helps class imbalance)
class_labels = train_generator.classes
class_weights = compute_class_weight('balanced', classes=np.unique(class_labels), y=class_labels)
class_weights = dict(enumerate(class_weights))
print("Class Weights:", class_weights)

NUM_CLASSES = train_generator.num_classes


# -------------------------------------------------------
# MODEL (EfficientNetB2 Fine-Tuned)
# -------------------------------------------------------
base_model = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(260,260,3))
base_model.trainable = True
for layer in base_model.layers[:-80]:
    layer.trainable = False

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),
    Dropout(0.5),
    Dense(NUM_CLASSES, activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),
    metrics=['accuracy']
)

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6)
checkpoint = ModelCheckpoint('best_efficientnetB2_finetuned.keras', monitor='val_accuracy', save_best_only=True)

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=NUM_EPOCHS,
    class_weight=class_weights,
    callbacks=[early_stopping, reduce_lr, checkpoint]
)


# -------------------------------------------------------
# TRAINING CURVES
# -------------------------------------------------------
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("Loss Curve")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title("Accuracy Curve")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()


# -------------------------------------------------------
# CONFUSION MATRIX & CLASSIFICATION REPORT
# -------------------------------------------------------
y_true = val_generator.classes
y_pred = np.argmax(model.predict(val_generator), axis=1)

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=val_generator.class_indices.keys())
plt.figure(figsize=(10,10))
disp.plot(cmap="Blues", xticks_rotation='vertical')
plt.title("Confusion Matrix")
plt.show()

print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=val_generator.class_indices.keys()))


# -------------------------------------------------------
# t-SNE VISUALIZATION (Feature Embeddings)
# -------------------------------------------------------
feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-3].output)
features = feature_extractor.predict(val_generator).reshape(len(y_true), -1)

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
tsne_result = tsne.fit_transform(features)

plt.figure(figsize=(10,8))
scatter = plt.scatter(tsne_result[:,0], tsne_result[:,1], c=y_true, cmap="tab10", s=5)
plt.legend(scatter.legend_elements()[0], list(val_generator.class_indices.keys()), bbox_to_anchor=(1.05,1), loc='upper left')
plt.title("t-SNE Class Embedding Visualization")
plt.show()


# -------------------------------------------------------
# GRAD-CAM HEATMAPS
# -------------------------------------------------------
def grad_cam(model, img, layer_name='top_conv'):
    grad_model = tf.keras.Model([model.inputs], [model.get_layer(layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img)
        class_idx = np.argmax(predictions[0])
        loss = predictions[:, class_idx]
    grads = tape.gradient(loss, conv_outputs)[0]
    weights = tf.reduce_mean(grads, axis=(0,1))
    cam = np.dot(conv_outputs[0], weights.numpy())
    cam = np.maximum(cam, 0)
    cam = cv2.resize(cam, (260,260))
    cam = cam / cam.max()
    return cam

plt.figure(figsize=(12,10))
for i in range(5):
    img, _ = val_generator[i]
    img_in = img[0][np.newaxis,...]
    heatmap = grad_cam(model, img_in)
    plt.subplot(2,3,i+1)
    plt.imshow(img[0])
    plt.imshow(heatmap, cmap="jet", alpha=0.5)
    plt.axis('off')
plt.suptitle("Grad-CAM Heatmaps")
plt.show()


# -------------------------------------------------------
# MISCLASSIFIED EXAMPLES
# -------------------------------------------------------
mis_idx = np.where(y_true != y_pred)[0][:9]
plt.figure(figsize=(12,12))
for i, idx in enumerate(mis_idx):
    batch = idx // BATCH_SIZE
    pos = idx % BATCH_SIZE
    img, _ = val_generator[batch]
    plt.subplot(3,3,i+1)
    plt.imshow(img[pos])
    plt.title(f"True: {list(val_generator.class_indices.keys())[y_true[idx]]}\nPred: {list(val_generator.class_indices.keys())[y_pred[idx]]}", color="red")
    plt.axis('off')
plt.show()
